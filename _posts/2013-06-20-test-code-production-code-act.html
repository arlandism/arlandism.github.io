---
layout: article
title: 'Test Code >= Production Code: Act Accordingly'
date: '2013-06-20T18:39:00.003-07:00'
author: aml
tags: 
modified_time: '2013-06-20T18:39:57.950-07:00'
blogger_id: tag:blogger.com,1999:blog-1730093662423317857.post-3007918625253839899
blogger_orig_url: https://immutablearlandis.blogspot.com/2013/06/test-code-production-code-act.html
---

One solid point that Uncle Bob's "Clean Code" really tries to hit home is the value of testing and how important it is. Not only is testing important in and of itself, but it's important that your test code is as clean, maintainable, and robust as your production; maybe even more so. Undoubtedly, many will question the logic of this premise. After all, aren't tests supposed to supplement your code? Won't writing lengthier test code delay your production code output? The answer to the second question is yes, sort of. The answer to the first question is a big, fat "NO!".<br /><br />As the name implies, test-driven development means that your test code should be driving the design of your production code. What does this mean? It means that you write test code the way you imagine your code's interface. You watch that test fail. And then you write the corresponding interface to match that test, and that test only! This forces you to thoroughly test almost every loc in your system, and think long and hard about that system's design and implementation. For these reasons, test code should be thought of not as a supplement, but as the primary key to successful software design.<br /><br />Unfortunately, I've committed the sin of neglecting my test code. It's easy to do, but I won't make excuses. When you've got the idea for an interface in your head sometimes you just want to hammer out that test code without thinking. "Quick!", your mind says, "Before you lose that spark." I implore you not to listen. Writing good test code will not cause that spark to vanish, it will help it grow.<br /><br />"Clean Code" talks about the value of domain-specific language and how good test code should have it. This essentially means that your test code has grown so complex, and you've refactored it so much, that it's actually organically developed its own API. For some reason I didn't think of my test code this way. I viewed as a barrier to production and a chore; necessary, but undesired. I've revised my opinions on this matter. My test code does suck in some areas, but it has also enabled me to add features to my tic tac toe system faster than I thought possible. It has forced me to loosen coupling and remove unnecessary dependencies. It has helped me to understand my system as a whole and how it should work. And I thought that was it! I thought that after accomplishing these things then the test code functions as it should, but this isn't the case. Test code should continue to grow and be refactored as your application grows. If it doesn't, you'll find yourself breaking old tests with new feature additions.<br /><br />Right now, I have some test code that sternly disobeys the Open Closed principle. This principle says that your code should be open for extensions, but closed for modification. Any new feature you want to add should not cause you to revise old code. My tests are showing that I've violated this rule. With new features I want to add I break the old test code. And without going back and revising these old tests my tests will remain in the red. Let this serve as a lesson to the developer thinking of slacking on test code refactoring. It can, and will, come back to haunt you. I'm off to atone for my dreadful sins and make an offering of refactorization to the TDD deities.
